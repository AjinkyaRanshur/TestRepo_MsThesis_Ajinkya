âœ“ WandB initialized in Online mode
Files already downloaded and verified
Files already downloaded and verified
The Iteration0:
================================
+++++++++++++++
Loss of Layers
tensor(0.0193, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0066, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0056, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0060, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0064, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0067, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0071, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0074, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0078, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0081, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0189, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0061, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0052, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0055, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0059, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0063, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0066, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0070, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0076, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0182, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0061, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0051, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0054, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0058, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0061, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0064, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0068, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0071, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0074, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0197, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0065, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0055, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0059, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0063, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0066, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0070, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0077, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0080, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0185, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0060, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0051, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0054, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0058, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0061, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0064, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0067, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0070, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0193, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0065, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0054, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0057, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0061, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0065, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0068, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0072, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0076, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0079, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0184, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0062, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0052, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0055, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0058, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0062, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0065, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0068, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0072, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0075, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0194, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0063, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0053, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0057, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0061, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0064, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0068, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0071, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0075, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0078, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0194, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0064, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0056, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0060, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0063, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0067, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0070, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0077, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0080, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0200, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0066, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0055, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0059, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0063, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0067, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0070, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0074, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0077, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0080, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0205, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0067, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0057, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0061, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0065, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0069, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0072, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0076, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0079, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0082, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0193, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0066, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0055, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0058, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0062, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0065, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0069, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0072, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0075, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0079, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0184, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0063, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0053, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0056, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0059, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0063, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0066, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0069, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0072, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0075, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0201, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0067, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0057, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0060, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0064, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0067, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0071, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0074, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0077, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0080, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0194, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0068, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0058, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0061, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0065, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0068, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0072, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0075, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0078, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0081, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0192, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0068, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0059, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0063, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0067, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0070, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0076, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0080, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0083, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0195, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0069, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0060, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0063, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0067, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0070, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0074, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0077, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0080, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0083, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0197, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0064, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0067, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0070, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0076, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0079, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0082, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0085, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0193, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0070, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0062, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0065, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0069, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0072, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0075, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0078, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0080, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0083, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0197, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0064, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0067, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0070, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0076, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0079, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0082, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0084, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0194, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0072, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0062, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0065, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0068, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0070, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0076, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0078, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0081, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0203, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0078, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0069, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0072, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0075, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0077, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0079, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0081, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0083, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0086, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0207, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0078, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0071, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0075, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0077, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0080, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0082, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0084, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0086, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0088, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0185, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0065, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0068, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0071, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0073, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0074, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0076, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0078, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0080, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0208, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0083, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0076, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0079, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0082, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0084, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0086, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0089, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0091, device='cuda:1', grad_fn=<AddBackward0>)
+++++++++++++++
Loss of Layers
tensor(0.0093, device='cuda:1', grad_fn=<AddBackward0>)
Traceback (most recent call last):
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week6/main.py", line 192, in <module>
    main()
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week6/main.py", line 148, in main
    train_bool = fine_tuning_using_classification(net,save_dir, trainloader, testloader,config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week6/main.py", line 129, in fine_tuning_using_classification
    train_bool=recon_pc_training(net,trainloader,testloader,"fine_tuning",config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week6/recon_pc_train.py", line 160, in recon_pc_training
    running_loss.append(final_loss.item())
                        ^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7f92542032e0>
Traceback (most recent call last):
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 182, in teardown
    self._router.join()
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/threading.py", line 1149, in join
    self._wait_for_tstate_lock()
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/threading.py", line 1169, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
