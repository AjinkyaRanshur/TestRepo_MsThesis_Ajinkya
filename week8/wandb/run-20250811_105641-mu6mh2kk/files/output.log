âœ“ WandB initialized in Online mode
Files already downloaded and verified
Files already downloaded and verified
The Iteration0:
================================
Traceback (most recent call last):
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week6/main.py", line 192, in <module>
    main()
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week6/main.py", line 148, in main
    train_bool = fine_tuning_using_classification(net,save_dir, trainloader, testloader,config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week6/main.py", line 127, in fine_tuning_using_classification
    net.load_state_dict(torch.load(f'{config.load_model_path}/{config.model_name}_{iteration_index}.pth',
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/nn/modules/module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for Net:
	Missing key(s) in state_dict: "fc3.weight", "fc3.bias", "fc3_fb.weight", "fc3_fb.bias".
	size mismatch for fc1.weight: copying a param with shape torch.Size([84, 256]) from checkpoint, the shape in current model is torch.Size([512, 256]).
	size mismatch for fc1.bias: copying a param with shape torch.Size([84]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc2.weight: copying a param with shape torch.Size([10, 84]) from checkpoint, the shape in current model is torch.Size([256, 512]).
	size mismatch for fc2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fc2_fb.weight: copying a param with shape torch.Size([84, 10]) from checkpoint, the shape in current model is torch.Size([512, 256]).
	size mismatch for fc2_fb.bias: copying a param with shape torch.Size([84]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc1_fb.weight: copying a param with shape torch.Size([256, 84]) from checkpoint, the shape in current model is torch.Size([256, 512]).
