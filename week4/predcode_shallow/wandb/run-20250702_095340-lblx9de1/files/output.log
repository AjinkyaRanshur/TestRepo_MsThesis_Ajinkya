âœ“ WandB initialized in Online mode
Files already downloaded and verified
Files already downloaded and verified
Epoch:0 and AverageLoss:2.137069094211549
Epoch:1 and AverageLoss:1.6707983023065436
Epoch:2 and AverageLoss:1.4486947227317049
Epoch:3 and AverageLoss:1.2895733447330993
Epoch:4 and AverageLoss:1.1606639364491338
Epoch:5 and AverageLoss:1.069282705369203
Epoch:6 and AverageLoss:0.9878372425008612
Epoch:7 and AverageLoss:0.9225819194713212
Epoch:8 and AverageLoss:0.8645650584374547
Epoch:9 and AverageLoss:0.815271953182757
Epoch:10 and AverageLoss:0.7701303132659639
Epoch:11 and AverageLoss:0.7324258270470992
Epoch:12 and AverageLoss:0.6850899940409014
Epoch:13 and AverageLoss:0.650263178912575
Epoch:14 and AverageLoss:0.6126227262227432
Epoch:15 and AverageLoss:0.590283780070522
Epoch:16 and AverageLoss:0.5505816881613963
Epoch:17 and AverageLoss:0.524900723677462
Epoch:18 and AverageLoss:0.4917331246463844
Epoch:19 and AverageLoss:0.4627321919288172
Epoch:20 and AverageLoss:0.44118651248457486
Epoch:21 and AverageLoss:0.4068246757435372
Epoch:22 and AverageLoss:0.3884845237292902
Epoch:23 and AverageLoss:0.3740979311106455
Epoch:24 and AverageLoss:0.3456651931223662
Epoch:25 and AverageLoss:0.33604328010393225
Epoch:26 and AverageLoss:0.3203527976942184
Epoch:27 and AverageLoss:0.31294198985904687
Epoch:28 and AverageLoss:0.2982310155201751
Epoch:29 and AverageLoss:0.29373551499279565
Epoch:30 and AverageLoss:0.26601098247272587
Epoch:31 and AverageLoss:0.25547109793900225
Epoch:32 and AverageLoss:0.2441596762298623
Epoch:33 and AverageLoss:0.25052694846754486
Epoch:34 and AverageLoss:0.2534395278719685
Epoch:35 and AverageLoss:0.21681982707565703
Epoch:36 and AverageLoss:0.2315102010165029
Epoch:37 and AverageLoss:0.21354098250265316
Epoch:38 and AverageLoss:0.20196153367381267
Epoch:39 and AverageLoss:0.1927384666793639
Epoch:40 and AverageLoss:0.20393241558919478
Epoch:41 and AverageLoss:0.20170152945744108
Epoch:42 and AverageLoss:0.20497155993643318
Epoch:43 and AverageLoss:0.18008702497005158
Epoch:44 and AverageLoss:0.16673263917912912
Epoch:45 and AverageLoss:0.1709014719823742
Epoch:46 and AverageLoss:0.18199737470053956
Epoch:47 and AverageLoss:0.16084989457560317
Epoch:48 and AverageLoss:0.17580385973958104
Epoch:49 and AverageLoss:0.14742844083996684
Epoch:50 and AverageLoss:0.1666945482001585
Epoch:51 and AverageLoss:0.16028674176472532
Epoch:52 and AverageLoss:0.14421161613843936
Epoch:53 and AverageLoss:0.14525151105068834
Epoch:54 and AverageLoss:0.16574391880837244
Epoch:55 and AverageLoss:0.1648841129563501
Epoch:56 and AverageLoss:0.13600888951679171
Epoch:57 and AverageLoss:0.14949227679435098
Epoch:58 and AverageLoss:0.15421923622965356
Epoch:59 and AverageLoss:0.14346313099269672
Epoch:60 and AverageLoss:0.13992623252617886
Epoch:61 and AverageLoss:0.13659234414510715
Epoch:62 and AverageLoss:0.12682801037740982
Epoch:63 and AverageLoss:0.11325623233662084
Epoch:64 and AverageLoss:0.14041673321076822
Epoch:65 and AverageLoss:0.14140538621188886
Epoch:66 and AverageLoss:0.1597656011867249
Epoch:67 and AverageLoss:0.14288829649558
Epoch:68 and AverageLoss:0.13484257111883224
Epoch:69 and AverageLoss:0.12364241903376244
Forward Training Succesful
Epoch:0 and AverageLoss:nan
Epoch:1 and AverageLoss:nan
Epoch:2 and AverageLoss:nan
Epoch:3 and AverageLoss:nan
Epoch:4 and AverageLoss:nan
Epoch:5 and AverageLoss:nan
Epoch:6 and AverageLoss:nan
Epoch:7 and AverageLoss:nan
Epoch:8 and AverageLoss:nan
Epoch:9 and AverageLoss:nan
Epoch:10 and AverageLoss:nan
Traceback (most recent call last):
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week4/predcode_shallow/main.py", line 240, in <module>
    main()
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week4/predcode_shallow/main.py", line 174, in main
    train_bool = training_using_ff_fb(
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week4/predcode_shallow/main.py", line 98, in training_using_ff_fb
    feedback_training(net, trainloader, testloader, lr, momentum, save_dir,epochs,seed,device,batch_size)
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week4/predcode_shallow/back_train.py", line 58, in feedback_training
    final_loss.backward()
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
