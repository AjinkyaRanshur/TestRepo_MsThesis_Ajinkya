âœ“ WandB initialized in Online mode
Files already downloaded and verified
Files already downloaded and verified
The Iteration0:
================================
Epoch:0 and AverageLoss:4.387539257478836
Epoch:1 and AverageLoss:2.9342907572646277
Epoch:2 and AverageLoss:2.262898482325132
Epoch:3 and AverageLoss:2.165433433354663
Epoch:4 and AverageLoss:2.0462411648172245
Epoch:5 and AverageLoss:1.9510495092557825
Epoch:6 and AverageLoss:1.8408729206875463
Epoch:7 and AverageLoss:1.7188309068265168
Epoch:8 and AverageLoss:1.6337116654876553
Epoch:9 and AverageLoss:1.5712837828394701
Epoch:10 and AverageLoss:1.515958700948359
Epoch:11 and AverageLoss:1.4776058389097833
Epoch:12 and AverageLoss:1.4398326803656185
Epoch:13 and AverageLoss:1.4065017544704934
Epoch:14 and AverageLoss:1.3713791461856775
Epoch:15 and AverageLoss:1.3427388280858774
Epoch:16 and AverageLoss:1.3151335502829393
Epoch:17 and AverageLoss:1.2790717889585763
Epoch:18 and AverageLoss:1.2575697616847885
Epoch:19 and AverageLoss:1.2308186838389052
Epoch:20 and AverageLoss:1.1981201139862274
Epoch:21 and AverageLoss:1.1759989212845903
Epoch:22 and AverageLoss:1.149308764263797
Epoch:23 and AverageLoss:1.1214813367485086
Epoch:24 and AverageLoss:1.0990029591733537
Epoch:25 and AverageLoss:1.0724655412651998
Epoch:26 and AverageLoss:1.0510592954542937
Epoch:27 and AverageLoss:1.02797634186952
Epoch:28 and AverageLoss:1.0073951938573051
Epoch:29 and AverageLoss:0.9882606149024671
Epoch:30 and AverageLoss:0.9655132501021676
Epoch:31 and AverageLoss:0.9447569371489308
Epoch:32 and AverageLoss:0.9260642366945896
Epoch:33 and AverageLoss:0.9102667085350017
Epoch:34 and AverageLoss:0.8892372034089949
Epoch:35 and AverageLoss:0.8741952671724207
Epoch:36 and AverageLoss:0.8574173194368172
Epoch:37 and AverageLoss:0.8416713733807244
Epoch:38 and AverageLoss:0.8243562634033925
Epoch:39 and AverageLoss:0.8063119957819009
Epoch:40 and AverageLoss:0.7955289245261561
Epoch:41 and AverageLoss:0.7789583946280467
Epoch:42 and AverageLoss:0.7661766841283539
Epoch:43 and AverageLoss:0.7562253690131789
Epoch:44 and AverageLoss:0.7393837807428502
Epoch:45 and AverageLoss:0.7246038137037126
Epoch:46 and AverageLoss:0.7126008196712454
Epoch:47 and AverageLoss:0.7021235048466021
Epoch:48 and AverageLoss:0.6875792324847882
Epoch:49 and AverageLoss:0.6753839261239142
Epoch:50 and AverageLoss:0.6591421130977934
Epoch:51 and AverageLoss:0.648444839908034
Epoch:52 and AverageLoss:0.6390181430770309
Epoch:53 and AverageLoss:0.623041781394378
Epoch:54 and AverageLoss:0.6166954324830829
Epoch:55 and AverageLoss:0.6028964603343583
Epoch:56 and AverageLoss:0.5853011738461302
Epoch:57 and AverageLoss:0.5766553701951985
Epoch:58 and AverageLoss:0.5624261787327964
Epoch:59 and AverageLoss:0.5574497479154631
Epoch:60 and AverageLoss:0.5419212410517056
Epoch:61 and AverageLoss:0.528485597551936
Epoch:62 and AverageLoss:0.5196177382450884
Epoch:63 and AverageLoss:0.5066720890572004
Epoch:64 and AverageLoss:0.49463654791607575
Epoch:65 and AverageLoss:0.4834991611940477
Epoch:66 and AverageLoss:0.4710520919783951
Epoch:67 and AverageLoss:0.46686253774806363
Epoch:68 and AverageLoss:0.4490603907105258
Epoch:69 and AverageLoss:0.4358051129619179
Epoch:70 and AverageLoss:0.42541686843728166
Traceback (most recent call last):
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 305, in <module>
    main()
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 247, in main
    train_bool = fine_tuning(save_dir, trainloader, testloader, net,epochs,seed,device,timesteps,batch_size,noise_type,noise_param,model_path)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 161, in fine_tuning
    train_bool = training_using_reconstruction_and_predicitve_coding(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 137, in training_using_reconstruction_and_predicitve_coding
    recon_pc_training(
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week5/recon_pc_train.py", line 121, in recon_pc_training
    for batch_idx,batch in enumerate(trainloader):
                           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torchvision/datasets/cifar.py", line 116, in __getitem__
    img = Image.fromarray(img)
          ^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/PIL/Image.py", line 3331, in fromarray
    obj = obj.tobytes()
          ^^^^^^^^^^^^^
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7f316af63600>
Traceback (most recent call last):
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 182, in teardown
    self._router.join()
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/threading.py", line 1149, in join
    self._wait_for_tstate_lock()
  File "/home/ajinkya/miniconda3/envs/cuda_pyt/lib/python3.12/threading.py", line 1169, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
