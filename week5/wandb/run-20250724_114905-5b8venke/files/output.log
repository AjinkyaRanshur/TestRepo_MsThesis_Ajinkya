âœ“ WandB initialized in Online mode
Files already downloaded and verified
Files already downloaded and verified
Epoch:0 and AverageLoss:0.18795151670575141
Epoch:1 and AverageLoss:0.12373958657979965
Epoch:2 and AverageLoss:0.10502656807899476
Epoch:3 and AverageLoss:0.09243012315034867
Epoch:4 and AverageLoss:0.08302322427034378
Epoch:5 and AverageLoss:0.07595329248309135
Epoch:6 and AverageLoss:0.07044961739182472
Epoch:7 and AverageLoss:0.06592042764425278
Epoch:8 and AverageLoss:0.06203816640675068
Epoch:9 and AverageLoss:0.05864201298356056
Epoch:10 and AverageLoss:0.05564587813615799
Epoch:11 and AverageLoss:0.05299415124952793
Epoch:12 and AverageLoss:0.05064450942873955
Epoch:13 and AverageLoss:0.048561335521936415
Epoch:14 and AverageLoss:0.046712610712647436
Epoch:15 and AverageLoss:0.045068596270680425
Epoch:16 and AverageLoss:0.04360150990486145
Epoch:17 and AverageLoss:0.042286345636844636
Epoch:18 and AverageLoss:0.041100566281378266
Epoch:19 and AverageLoss:0.040024979835748674
Epoch:20 and AverageLoss:0.03904299950897694
Epoch:21 and AverageLoss:0.03814136712402105
Epoch:22 and AverageLoss:0.03730860370397568
Epoch:23 and AverageLoss:0.03653589707612991
Epoch:24 and AverageLoss:0.035815264503657816
Epoch:25 and AverageLoss:0.03514097169935703
Epoch:26 and AverageLoss:0.03450737131983042
Epoch:27 and AverageLoss:0.03391061157286167
Epoch:28 and AverageLoss:0.03334723338782787
Epoch:29 and AverageLoss:0.032813888143002984
Epoch:30 and AverageLoss:0.03230765045434236
Epoch:31 and AverageLoss:0.03182661936283111
Epoch:32 and AverageLoss:0.03136871786415577
Epoch:33 and AverageLoss:0.03093178816139698
Epoch:34 and AverageLoss:0.03051424817889929
Epoch:35 and AverageLoss:0.030114928165078162
Epoch:36 and AverageLoss:0.02973190985620022
Epoch:37 and AverageLoss:0.02936463115364313
Epoch:38 and AverageLoss:0.029011694553494453
Epoch:39 and AverageLoss:0.02867204974144697
Epoch:40 and AverageLoss:0.028344943201541902
Epoch:41 and AverageLoss:0.02802951085716486
Epoch:42 and AverageLoss:0.027725026197731494
Epoch:43 and AverageLoss:0.027431028574705123
Epoch:44 and AverageLoss:0.0271464745298028
Traceback (most recent call last):
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 278, in <module>
    main()
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 217, in main
    train_bool = training_using_reconstruction_and_predicitve_coding(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 137, in training_using_reconstruction_and_predicitve_coding
    recon_pc_training(
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week5/recon_pc_train.py", line 46, in recon_pc_training
    ft_AB_pc_temp,ft_BC_pc_temp,ft_CD_pc_temp,ft_DE_pc_temp,loss_of_layers=net.recon_predictive_coding_pass(images,ft_AB_pc_temp,ft_BC_pc_temp,ft_CD_pc_temp,ft_DE_pc_temp,beta,gamma,alpha,images.size(0))
                                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week5/network.py", line 151, in recon_predictive_coding_pass
    ft_AB_pc = gamma_AB_fwd*self.conv1(x) + (1-gamma_AB_fwd-beta_AB_bck) * ft_AB + beta_AB_bck*self.deconv2_fb(self.upsample(ft_BC))-alpha_AB*scalingB*batch_size*reconstructionB
                                                                                                               ^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/nn/modules/upsampling.py", line 172, in forward
    return F.interpolate(
           ^^^^^^^^^^^^^^
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/nn/functional.py", line 4580, in interpolate
    return torch._C._nn.upsample_bilinear2d(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7fa62f45a020>
Traceback (most recent call last):
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/wandb/sdk/lib/service_connection.py", line 90, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/wandb/sdk/lib/service_connection.py", line 218, in teardown
    self._router.join()
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/threading.py", line 1149, in join
    self._wait_for_tstate_lock()
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/threading.py", line 1169, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
