âœ“ WandB initialized in Online mode
Files already downloaded and verified
Files already downloaded and verified
Epoch:0 and AverageLoss:0.2729101020204442
Traceback (most recent call last):
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 278, in <module>
    main()
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 217, in main
    train_bool = training_using_reconstruction_and_predicitve_coding(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 137, in training_using_reconstruction_and_predicitve_coding
    recon_pc_training(
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week5/recon_pc_train.py", line 57, in recon_pc_training
    test_loss=recon_pc_loss(net,testloader,batch_size,beta,gamma,alpha,device,criterion,timesteps)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week5/eval_and_plotting.py", line 86, in recon_pc_loss
    ft_AB_pc_temp,ft_BC_pc_temp,ft_CD_pc_temp,ft_DE_pc_temp,loss_of_layers=net.recon_predictive_coding_pass(images,ft_AB_pc_temp,ft_BC_pc_temp,ft_CD_pc_temp,ft_DE_pc_temp,beta,gamma,alpha,images.size(0))
                                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkyar/projects/TestRepo_MsThesis_Ajinkya/week5/network.py", line 142, in recon_predictive_coding_pass
    reconstructionB=torch.autograd.grad(errorB,ft_AB,retain_graph=True)[0]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/autograd/__init__.py", line 496, in grad
    result = _engine_run_backward(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkyar/miniconda3/envs/cuda_pyt/lib/python3.12/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
