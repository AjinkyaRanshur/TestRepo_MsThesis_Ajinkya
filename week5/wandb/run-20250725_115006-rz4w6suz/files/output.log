âœ“ WandB initialized in Online mode
Files already downloaded and verified
Files already downloaded and verified
Epoch:0 and AverageLoss:0.260661734415747
Epoch:1 and AverageLoss:0.12118104936750344
Traceback (most recent call last):
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 278, in <module>
    main()
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 217, in main
    train_bool = training_using_reconstruction_and_predicitve_coding(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week5/main.py", line 137, in training_using_reconstruction_and_predicitve_coding
    recon_pc_training(
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week5/recon_pc_train.py", line 59, in recon_pc_training
    test_loss=recon_pc_loss(net,testloader,batch_size,beta,gamma,alpha,device,criterion,timesteps)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week5/eval_and_plotting.py", line 86, in recon_pc_loss
    ft_AB_pc_temp,ft_BC_pc_temp,ft_CD_pc_temp,ft_DE_pc_temp,loss_of_layers=net.recon_predictive_coding_pass(images,ft_AB_pc_temp,ft_BC_pc_temp,ft_CD_pc_temp,ft_DE_pc_temp,beta,gamma,alpha,images.size(0))
                                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ajinkya/projects/TestRepo_MsThesis_Ajinkya/week5/network.py", line 186, in recon_predictive_coding_pass
    ft_DE_pc=gamma_DE_fwd*self.conv4(pooled_ft_CD_pc) + (1-gamma_DE_fwd) * ft_DE - alpha_DE*scalingE*batch_size*reconstructionE
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 1 has a total capacity of 44.56 GiB of which 1.31 MiB is free. Including non-PyTorch memory, this process has 44.56 GiB memory in use. Of the allocated memory 43.07 GiB is allocated by PyTorch, and 29.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
